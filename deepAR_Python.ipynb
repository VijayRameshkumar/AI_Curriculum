{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayRameshkumar/AI_Curriculum/blob/master/deepAR_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXYh0D4petw6",
        "outputId": "9ba8c97b-213d-427b-ca29-92d17ecdb7d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSrJwU0Mq5Jc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9b2872-679a-4aa0-eb3e-c43b8e46a7a4"
      },
      "source": [
        "! pip install --upgrade mxnet-cu101\n",
        "! pip install gluonts==0.7.5\n",
        "\n",
        "# !pip install --upgrade mxnet-cu110"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mxnet-cu101 in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-cu101) (1.22.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-cu101) (2.27.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet-cu101) (0.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gluonts==0.7.5 in /usr/local/lib/python3.10/dist-packages (0.7.5)\n",
            "Requirement already satisfied: holidays>=0.9 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.7.5) (0.27)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.7.5) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.7.5) (1.22.4)\n",
            "Requirement already satisfied: pandas~=1.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.7.5) (1.5.3)\n",
            "Requirement already satisfied: pydantic~=1.1 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.7.5) (1.10.9)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.7.5) (4.65.0)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.7.5) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from holidays>=0.9->gluonts==0.7.5) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gluonts==0.7.5) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gluonts==0.7.5) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gluonts==0.7.5) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gluonts==0.7.5) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gluonts==0.7.5) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gluonts==0.7.5) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gluonts==0.7.5) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.0->gluonts==0.7.5) (2022.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=1.1->gluonts==0.7.5) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->holidays>=0.9->gluonts==0.7.5) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "IlL_FnprbKi6",
        "outputId": "549d922a-5c4a-4d7c-9416-11dc56c5b6a8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# url = '/content/drive/MyDrive/PM_data/RX_util_huawei.csv'\n",
        "# url = '/content/drive/MyDrive/PM_data/Temp_3KPI_1.csv'\n",
        "# url = '/content/drive/MyDrive/RX_hu_Sample.csv'\n",
        "url = '/content/drive/MyDrive/RX_NEC_Sample.csv'\n",
        "\n",
        "df = pd.read_csv(url, date_parser=True)\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-66df769f071e>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/RX_NEC_Sample.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/RX_NEC_Sample.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38M0ecitrIew"
      },
      "source": [
        "df.object_id.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUTzz9RSlRxd",
        "outputId": "7c540396-590a-4cbd-86ba-1cef0f828a22"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import argparse\n",
        "\n",
        "from gluonts.model.deepar import DeepAREstimator\n",
        "from gluonts.mx.trainer import Trainer\n",
        "from gluonts.dataset.common import ListDataset\n",
        "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
        "from gluonts.evaluation import Evaluator\n",
        "from gluonts.dataset.field_names import FieldName\n",
        "from gluonts.dataset.util import to_pandas\n",
        "from gluonts.mx.trainer.model_averaging import ModelAveraging, SelectNBestSoftmax, SelectNBestMean\n",
        "from gluonts.mx.trainer.learning_rate_scheduler import LearningRateReduction\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (10, 8)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "print(\"Number GPU's: \" + str(mx.context.num_gpus()))\n",
        "\n",
        "class DeepAR():\n",
        "\n",
        "    def __init__(self, isObj, data, context_length, prediction_length, freq, KPI_ID, epoch, datetime, kpi_value='kpi_value'):\n",
        "        self.data = data\n",
        "        self.isObj = isObj\n",
        "        self.context_length = context_length\n",
        "        self.prediction_length = prediction_length\n",
        "        self.freq = freq\n",
        "        self.NO_NES = 1\n",
        "        self.KPI_ID = KPI_ID\n",
        "        self.epoch = epoch\n",
        "        self.kpi_value = kpi_value\n",
        "        self.cols = None\n",
        "        self.tss = None\n",
        "        self.forecast = None\n",
        "        self.objects = None\n",
        "        self.nodes = None\n",
        "        self.datetime = datetime\n",
        "\n",
        "        if self.datetime == 'nrt':\n",
        "            self.datetime = 'ne_datetime'\n",
        "            self.cols = \"sub_ne_type,ne_id,object_id,kpi_value,max_value,min_value,kpi_id,algorithm,type,ne_datetime,ne_date,fw_kpi_value,fw_max_value,fw_min_value,confidence\".split(\",\")\n",
        "\n",
        "        elif self.datetime == 'Days':\n",
        "            self.datetime = 'ne_date'\n",
        "            self.cols = 'sub_ne_type,ne_id,object_id,kpi_value,max_value,min_value,kpi_id,algorithm,type,ne_date,fw_kpi_value,fw_max_value,fw_min_value,confidence'.split(',')\n",
        "\n",
        "        elif self.datetime=='Hours':\n",
        "            self.cols = 'sub_ne_type,ne_id,object_id,kpi_value,max_value,min_value,fw_kpi_value,fw_max_value,fw_min_value,kpi_id,algorithm,type,ne_datetime,ne_date,confidence'.split(',')\n",
        "            self.datetime = 'ne_datetime'\n",
        "\n",
        "    def impute(self, df):\n",
        "        print(f\"Before total number of nan in dataset {df.isnull().sum().sum()}\")\n",
        "        if df.isnull().sum().sum() != 0:\n",
        "            for i in df.columns:\n",
        "                df[i] = df[i].interpolate(limit=260, method='spline', order=1, limit_direction='forward')\n",
        "                df[i] = df[i].fillna(df[i].mean())\n",
        "        print(f\"After total number of nan in dataset {df.isnull().sum().sum()}\")\n",
        "        return df\n",
        "\n",
        "    def preprocessing(self, ):\n",
        "        print(\"I'm in preprocessing : \")\n",
        "        df = self.data\n",
        "\n",
        "        if df.isnull().sum().sum() != 0:\n",
        "            df = self.impute(df)\n",
        "\n",
        "        if self.isObj:\n",
        "            self.objects = df.object_id.values.tolist()\n",
        "            self.nodes = df.ne_id.values.tolist()\n",
        "            df = pd.pivot_table(index='object_id', columns=self.datetime, values=self.kpi_value, data=df)\n",
        "        else:\n",
        "            self.nodes = df.ne_id.values.tolist()\n",
        "            df = pd.pivot_table(index='ne_id', columns=self.datetime, values=self.kpi_value, data=df)\n",
        "        print(f\"df shape {df.shape}\")\n",
        "        self.data = df\n",
        "\n",
        "    def get_feature_label(self, ):\n",
        "        return self.data.index.astype('category').codes.astype('int')\n",
        "\n",
        "    def train_test_split(self, ):\n",
        "        self.preprocessing()\n",
        "        print(\"I'm in train test split : \")\n",
        "        df_train = self.data\n",
        "        df_test = self.data.iloc[:, -self.context_length:]\n",
        "\n",
        "        self.NO_NES = df_train.shape[0]\n",
        "        start_train = pd.Timestamp(df_train.columns[0], freq=self.freq)\n",
        "        start_test = pd.Timestamp(df_test.columns[0], freq=self.freq)\n",
        "\n",
        "        print(f\"train dataset shape : {df_train.shape}\\ntest dataset shape : {df_test.shape}\")\n",
        "        return df_train.values, df_test.values, start_train, start_test\n",
        "\n",
        "    def prepare_dataset(self, ):\n",
        "        df_train, df_test, start_train, start_test = self.train_test_split()\n",
        "        # print(\"I'm in before ts_code\")\n",
        "        ts_code = self.get_feature_label()\n",
        "\n",
        "        # print(\"I'm in before train_ds\")\n",
        "\n",
        "        train_ds = ListDataset([\n",
        "                        {\n",
        "                            FieldName.TARGET : target,\n",
        "                            FieldName.START : start_train,\n",
        "                            FieldName.FEAT_STATIC_CAT:fsc\n",
        "                        }\n",
        "                        for (target, fsc) in zip(df_train[:], ts_code[:].reshape(-1, 1))\n",
        "                        ], freq=self.freq)\n",
        "\n",
        "        # print(\"I'm in before test_ds\")\n",
        "\n",
        "        test_ds = ListDataset([\n",
        "                                {\n",
        "                                    FieldName.TARGET : target,\n",
        "                                    FieldName.START : start_test,\n",
        "                                    FieldName.FEAT_STATIC_CAT:fsc\n",
        "                                }\n",
        "                                for (target, fsc) in zip(df_test, ts_code.reshape(-1, 1))\n",
        "                                ], freq=self.freq)\n",
        "        return train_ds, test_ds\n",
        "\n",
        "    def model_instantiate(self, ):\n",
        "        callbacks = [\n",
        "                     LearningRateReduction(objective=\"min\",patience=2,\n",
        "                                           base_lr=1e-4,\n",
        "                                           decay_factor=0.6),\n",
        "                     ModelAveraging(avg_strategy=SelectNBestMean(num_models=2))]\n",
        "\n",
        "        estimator = DeepAREstimator(mx.context.gpu(0),\n",
        "                            freq=self.freq,\n",
        "                            context_length=self.context_length,\n",
        "                            prediction_length=self.prediction_length,\n",
        "                            num_layers=8,\n",
        "                            num_cells=256,\n",
        "                            use_feat_static_cat=True,\n",
        "                            cardinality=[1],\n",
        "                            cell_type='gru',\n",
        "                            trainer=Trainer(epochs=self.epoch, callbacks=callbacks),\n",
        "                            batch_size=128,\n",
        "                            impute_missing_values=True,\n",
        "                            num_imputation_samples=3)\n",
        "        return estimator\n",
        "\n",
        "    def sample_df(self, forecast):\n",
        "        samples = forecast.samples\n",
        "        ns, h = samples.shape\n",
        "        dates = pd.date_range(forecast.start_date, freq=forecast.freq, periods=h)\n",
        "        return pd.DataFrame(samples.T, index=dates)\n",
        "\n",
        "    def model_train(self, ):\n",
        "        print(\"dataset preparation :\")\n",
        "        train_ds, test_ds = self.prepare_dataset()\n",
        "\n",
        "        print(\"model instantiate :\")\n",
        "        estimator = self.model_instantiate()\n",
        "\n",
        "        print(\"model training :\")\n",
        "        predictor = estimator.train(training_data=train_ds)\n",
        "\n",
        "        print(\"forecasting\")\n",
        "        forecast_it, ts_it = make_evaluation_predictions(dataset = test_ds, predictor=predictor, num_samples=1)\n",
        "        forecast_it_, ts_it_ = make_evaluation_predictions(dataset = train_ds, predictor=predictor, num_samples=1)\n",
        "\n",
        "        print(\"obtaining time series conditionning values ...\")\n",
        "        tss = list(tqdm(ts_it, total=len(test_ds)))\n",
        "        tss_ = list(tqdm(ts_it_, total=len(train_ds)))\n",
        "\n",
        "        print(\"obtaining time series prediction\")\n",
        "        forecasts = list(tqdm(forecast_it, total=len(test_ds)))\n",
        "        forecasts_ = list(tqdm(forecast_it_, total=len(train_ds)))\n",
        "        # forecasts = self.sample_df(forecasts)\n",
        "\n",
        "        print(\"Evaluation\")\n",
        "        evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
        "        agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n",
        "        agg_metrics_, item_metrics_ = evaluator(iter(tss_), iter(forecasts_), num_series=len(train_ds))\n",
        "\n",
        "        print(f\"TRAIN MEAN MAE : {item_metrics_.abs_error.mean()}\")\n",
        "        print(f\"TEST MEAN MAE : {item_metrics.abs_error.mean()}\\n\")\n",
        "\n",
        "        print(f\"TRAIN MEAN MSE : {item_metrics_.MSE.mean()}\")\n",
        "        print(f\"TEST MEAN MSE : {item_metrics.MSE.mean()}\\n\")\n",
        "\n",
        "        print(f\"TRAIN MEAN RMSE : {math.sqrt(item_metrics_.MSE.mean())}\")\n",
        "        print(f\"TEST MEAN RMSE : {math.sqrt(item_metrics.MSE.mean())}\\n\")\n",
        "\n",
        "        print(f\"TRAIN MEAN MAPE : {item_metrics_.MAPE.mean()}\")\n",
        "        print(f\"TEST MEAN MAPE : {item_metrics.MAPE.mean()}\")\n",
        "\n",
        "        self.tss = tss\n",
        "        self.forecast = forecasts\n",
        "\n",
        "        # forecasts_ = list(forecast_it_)\n",
        "        # tss_ = list(ts_it_)\n",
        "        # ts_entry_ = tss_[0]\n",
        "        # forecast_entry_ = forecasts_[0]\n",
        "\n",
        "        # forecasts = list(forecast_it)\n",
        "        # tss = list(ts_it)\n",
        "        # ts_entry = tss[0]\n",
        "        # forecast_entry = forecasts[0]\n",
        "\n",
        "        return predictor, train_ds, test_ds, (tss_, forecasts_), (tss, forecasts)\n",
        "\n",
        "    def get_sma(self, values, rate):\n",
        "        return values.rolling(rate).mean()\n",
        "\n",
        "    def get_bollinger_bands(self, values, rate=2):\n",
        "        sma = self.get_sma(values, rate)\n",
        "        std = values.rolling(rate).std()\n",
        "        bollinger_up = sma + std * 2 # Calculate top band\n",
        "        bollinger_down = sma - std * 2 # Calculate bottom band\n",
        "        return bollinger_up, bollinger_down\n",
        "\n",
        "    def predict(self, ):\n",
        "        predictor, train_ds, test_ds, train, test = self.model_train()\n",
        "        dt = []\n",
        "\n",
        "        for index, i in tqdm(enumerate(list(predictor.predict(test_ds, num_samples=1)))):\n",
        "            ts_entry = self.sample_df(i).reset_index().rename(columns={'index' : 'ne_datetime'})\n",
        "            ts_entry.columns = ['ne_date_time', 'kpi_value']\n",
        "\n",
        "            ts_entry['ne_date_time'] = pd.to_datetime(ts_entry['ne_date_time'])\n",
        "            ts_entry['ne_date'] = ts_entry['ne_date_time'].dt.date\n",
        "            ts_entry['kpi_value'] = ts_entry['kpi_value'].astype('float32').abs()\n",
        "            ts_entry['kpi_value'].fillna(value=ts_entry['kpi_value'].mean(), inplace=True)\n",
        "            max, min = self.get_bollinger_bands(ts_entry['kpi_value'])\n",
        "            ts_entry['max_value'] = pd.Series(max)\n",
        "            ts_entry['min_value'] = pd.Series(min)\n",
        "            ts_entry['min_value'].fillna(value=ts_entry['min_value'].mean(), inplace=True)\n",
        "            ts_entry['max_value'].fillna(value=ts_entry['max_value'].mean(), inplace=True)\n",
        "            ts_entry['kpi_id'] = self.KPI_ID\n",
        "            ts_entry['algorithm'] = 'NeuralNetwork'\n",
        "\n",
        "            if self.isObj:\n",
        "                ts_entry['object_id'] = self.objects[index]\n",
        "                ts_entry['ne_id'] = self.nodes[index]\n",
        "                ts_entry['type'] = 0\n",
        "                ts_entry['fw_kpi_value'] = 0\n",
        "                ts_entry['fw_max_value'] = 0\n",
        "                ts_entry['fw_min_value'] = 0\n",
        "                ts_entry['confidence'] = 0.95\n",
        "            else:\n",
        "                ts_entry['object_id'] = '-'\n",
        "                ts_entry['ne_id'] = self.nodes[index]\n",
        "                ts_entry['type'] = 1\n",
        "                ts_entry['fw_kpi_value'] = 0\n",
        "                ts_entry['fw_max_value'] = 0\n",
        "                ts_entry['fw_min_value'] = 0\n",
        "                ts_entry['confidence'] = 0.95\n",
        "\n",
        "            ts_entry['sub_ne_type'] = \"\"\n",
        "            dt.append(ts_entry)\n",
        "\n",
        "        dt = pd.concat(dt).reset_index(drop=True)\n",
        "        cols = self.cols\n",
        "        return dt[cols], train_ds, test_ds, predictor, train, test\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\n",
        "#     url = '/content/drive/MyDrive/RX_hu_Sample.csv'\n",
        "#     df = pd.read_csv(url, date_parser=True)\n",
        "#     result = DeepAR(isObj=True, data=df, context_length=5, prediction_length=3, freq='D', KPI_ID='21691544429562887',\n",
        "#                     epoch=2, datetime='Days', kpi_value='value')\n",
        "#     T = r.predict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonts/json.py:46: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
            "  \"Using `json`-module for json-handling. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number GPU's: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN1U1apgW24c",
        "outputId": "33dd5ce5-ef6e-45a6-e507-4c5825fc34f0"
      },
      "source": [
        "from gluonts.dataset.util import to_pandas\n",
        "# from DeepAR import DeepAR\n",
        "\n",
        "# from DeepAR import DeepAR\n",
        "# '1D' - 1 Day\n",
        "# '1H' - 1 Hour\n",
        "# '1M' - 1 Month\n",
        "# '1Y' - 1 Year\n",
        "# '1s' - 1 Second\n",
        "# '1min' - 1 Minute\n",
        "\n",
        "\n",
        "r = DeepAR(isObj=True, data=df, context_length=10, prediction_length=5, freq='D', KPI_ID='RX_NEC',\n",
        "           epoch=5, datetime='Days', kpi_value='kpi_value')\n",
        "\n",
        "dt, train_ds, test_ds, predictor, train, test = r.predict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset preparation :\n",
            "I'm in preprocessing : \n",
            "df shape (3, 15)\n",
            "I'm in train test split : \n",
            "train dataset shape : (3, 15)\n",
            "test dataset shape : (3, 10)\n",
            "model instantiate :\n",
            "model training :\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:25<00:00,  1.97it/s, epoch=1/5, avg_epoch_loss=1.17]\n",
            "100%|██████████| 50/50 [00:09<00:00,  5.30it/s, epoch=2/5, avg_epoch_loss=0.43]\n",
            "100%|██████████| 50/50 [00:09<00:00,  5.24it/s, epoch=3/5, avg_epoch_loss=0.288]\n",
            "100%|██████████| 50/50 [00:09<00:00,  5.31it/s, epoch=4/5, avg_epoch_loss=0.0361]\n",
            "100%|██████████| 50/50 [00:09<00:00,  5.20it/s, epoch=5/5, avg_epoch_loss=-.0984]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forecasting\n",
            "obtaining time series conditionning values ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 1215.27it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 1953.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obtaining time series prediction\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00,  5.03it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00,  5.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running evaluation: 100%|██████████| 3/3 [00:00<00:00, 52.04it/s]/usr/local/lib/python3.7/dist-packages/gluonts/evaluation/metrics.py:102: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return np.mean(np.abs(target - forecast)) / seasonal_error\n",
            "/usr/local/lib/python3.7/dist-packages/gluonts/evaluation/metrics.py:150: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return numerator / seasonal_error\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/cast.py:1625: UserWarning: Warning: converting a masked element to nan.\n",
            "  subarr = np.array(values, dtype=dtype, copy=copy)\n",
            "Running evaluation: 100%|██████████| 3/3 [00:00<00:00, 68.00it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gluonts/evaluation/metrics.py:102: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return np.mean(np.abs(target - forecast)) / seasonal_error\n",
            "/usr/local/lib/python3.7/dist-packages/gluonts/evaluation/metrics.py:150: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return numerator / seasonal_error\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN MEAN MAE : 2.2919697364171348\n",
            "TEST MEAN MAE : 3.1934796969095864\n",
            "\n",
            "TRAIN MEAN MSE : 0.5093118717273076\n",
            "TEST MEAN MSE : 0.7678727596998214\n",
            "\n",
            "TRAIN MEAN RMSE : 0.7136608940717627\n",
            "TEST MEAN RMSE : 0.8762834927692187\n",
            "\n",
            "TRAIN MEAN MAPE : 0.3641509175300598\n",
            "TEST MEAN MAPE : 0.6333005666732788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3it [00:00, 74.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHdMxvFnkT7J"
      },
      "source": [
        "def sample_df(forecast):\n",
        "    samples = forecast.samples\n",
        "    ns, h = samples.shape\n",
        "    dates = pd.date_range(forecast.start_date, freq=forecast.freq, periods=h)\n",
        "    return pd.DataFrame(samples.T, index=dates)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ek37pbahdYW",
        "outputId": "ada75f1a-18f7-454e-f98e-f387f051fe75"
      },
      "source": [
        "print(df[df.object_id == 'SUM-LA-SDN-0558_1-0-0-0-8519680'].kpi_value.mean(),\n",
        "df[df.object_id == 'SUM-LA-SDN-0558_1-0-0-0-8585216'].kpi_value.mean(),\n",
        "df[df.object_id == 'SUM-LA-SDN-0558_1-0-0-0-8650752'].kpi_value.mean())\n",
        "# df['SUM-LA-SDN-0558_1-0-0-0-8650752']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9893333333333333 2.186 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6VMuB8MJkJLl",
        "outputId": "3bcd6aba-f56c-49af-e30a-dec73547d8a9"
      },
      "source": [
        "sample_df(train[1][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-10-07</th>\n",
              "      <td>1.602985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-08</th>\n",
              "      <td>1.066790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-09</th>\n",
              "      <td>0.498158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-10</th>\n",
              "      <td>1.504086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-11</th>\n",
              "      <td>1.116071</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   0\n",
              "2021-10-07  1.602985\n",
              "2021-10-08  1.066790\n",
              "2021-10-09  0.498158\n",
              "2021-10-10  1.504086\n",
              "2021-10-11  1.116071"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "XeLBl353i6Qh",
        "outputId": "fd868072-8b86-418e-a12b-745727edfae1"
      },
      "source": [
        "t = train[0][0]\n",
        "t['a'] = df[df.object_id == 'SUM-LA-SDN-0558_1-0-0-0-8519680'].kpi_value.reset_index(drop=True).values\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-09-27</th>\n",
              "      <td>1.08</td>\n",
              "      <td>1.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-28</th>\n",
              "      <td>1.60</td>\n",
              "      <td>1.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-29</th>\n",
              "      <td>1.51</td>\n",
              "      <td>1.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>1.28</td>\n",
              "      <td>1.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-01</th>\n",
              "      <td>1.02</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-02</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-03</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-04</th>\n",
              "      <td>1.20</td>\n",
              "      <td>1.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-05</th>\n",
              "      <td>1.09</td>\n",
              "      <td>1.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-06</th>\n",
              "      <td>0.86</td>\n",
              "      <td>0.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-07</th>\n",
              "      <td>1.12</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-08</th>\n",
              "      <td>0.99</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-09</th>\n",
              "      <td>0.96</td>\n",
              "      <td>0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-10</th>\n",
              "      <td>1.11</td>\n",
              "      <td>1.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-11</th>\n",
              "      <td>1.02</td>\n",
              "      <td>1.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0     a\n",
              "2021-09-27  1.08  1.08\n",
              "2021-09-28  1.60  1.60\n",
              "2021-09-29  1.51  1.51\n",
              "2021-09-30  1.28  1.28\n",
              "2021-10-01  1.02  1.02\n",
              "2021-10-02  0.00  0.00\n",
              "2021-10-03  0.00  0.00\n",
              "2021-10-04  1.20  1.20\n",
              "2021-10-05  1.09  1.09\n",
              "2021-10-06  0.86  0.86\n",
              "2021-10-07  1.12  1.12\n",
              "2021-10-08  0.99  0.99\n",
              "2021-10-09  0.96  0.96\n",
              "2021-10-10  1.11  1.11\n",
              "2021-10-11  1.02  1.02"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbYbld2mY9ZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "5c18006f-399a-4677-863f-960d68282981"
      },
      "source": [
        "t = train[0][1]\n",
        "t['a'] = df[df.object_id == 'SUM-LA-SDN-0558_1-0-0-0-8585216'].kpi_value.reset_index(drop=True).values\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-09-27</th>\n",
              "      <td>1.99</td>\n",
              "      <td>1.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-28</th>\n",
              "      <td>2.79</td>\n",
              "      <td>2.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-29</th>\n",
              "      <td>2.42</td>\n",
              "      <td>2.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>1.74</td>\n",
              "      <td>1.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-01</th>\n",
              "      <td>2.21</td>\n",
              "      <td>2.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-02</th>\n",
              "      <td>2.41</td>\n",
              "      <td>2.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-03</th>\n",
              "      <td>2.17</td>\n",
              "      <td>2.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-04</th>\n",
              "      <td>2.17</td>\n",
              "      <td>2.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-05</th>\n",
              "      <td>2.38</td>\n",
              "      <td>2.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-06</th>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-07</th>\n",
              "      <td>1.91</td>\n",
              "      <td>1.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-08</th>\n",
              "      <td>2.28</td>\n",
              "      <td>2.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-09</th>\n",
              "      <td>1.77</td>\n",
              "      <td>1.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-10</th>\n",
              "      <td>2.19</td>\n",
              "      <td>2.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-11</th>\n",
              "      <td>2.06</td>\n",
              "      <td>2.06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0     a\n",
              "2021-09-27  1.99  1.99\n",
              "2021-09-28  2.79  2.79\n",
              "2021-09-29  2.42  2.42\n",
              "2021-09-30  1.74  1.74\n",
              "2021-10-01  2.21  2.21\n",
              "2021-10-02  2.41  2.41\n",
              "2021-10-03  2.17  2.17\n",
              "2021-10-04  2.17  2.17\n",
              "2021-10-05  2.38  2.38\n",
              "2021-10-06  2.30  2.30\n",
              "2021-10-07  1.91  1.91\n",
              "2021-10-08  2.28  2.28\n",
              "2021-10-09  1.77  1.77\n",
              "2021-10-10  2.19  2.19\n",
              "2021-10-11  2.06  2.06"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "y6yO42WXj4mx",
        "outputId": "34ab5e3d-b1f6-47cd-b674-40c2320f7558"
      },
      "source": [
        "t = train[0][2]\n",
        "t['a'] = df[df.object_id == 'SUM-LA-SDN-0558_1-0-0-0-8650752'].kpi_value.reset_index(drop=True).values\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-09-27</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-29</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-09-30</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-01</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-02</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-03</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-04</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-05</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-07</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-09</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-10-11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0    a\n",
              "2021-09-27  0.0  0.0\n",
              "2021-09-28  0.0  0.0\n",
              "2021-09-29  0.0  0.0\n",
              "2021-09-30  0.0  0.0\n",
              "2021-10-01  0.0  0.0\n",
              "2021-10-02  0.0  0.0\n",
              "2021-10-03  0.0  0.0\n",
              "2021-10-04  0.0  0.0\n",
              "2021-10-05  0.0  0.0\n",
              "2021-10-06  0.0  0.0\n",
              "2021-10-07  0.0  0.0\n",
              "2021-10-08  0.0  0.0\n",
              "2021-10-09  0.0  0.0\n",
              "2021-10-10  0.0  0.0\n",
              "2021-10-11  0.0  0.0"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yyY9OimVdKk"
      },
      "source": [
        "def plot_prob_forecasts(ts_entry, forecast_entry, actual_entry):\n",
        "    plot_length = 150\n",
        "    prediction_intervals = (50.0, 90.0)\n",
        "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
        "    ts_entry[-plot_length:].plot(ax=ax)  # plot the time series\n",
        "    forecast_entry.plot(prediction_intervals=prediction_intervals, color='r')\n",
        "    actual_entry.plot(color='g')\n",
        "    plt.grid(which=\"both\")\n",
        "    plt.legend(legend, loc=\"upper left\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS2w-pZCPFpo"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xqRlEF3QWXv"
      },
      "source": [
        "for i in train[1]:\n",
        "    print(sample_df(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ukP4GIMcMq"
      },
      "source": [
        "o = df.object_id.unique()\n",
        "\n",
        "dfs = []\n",
        "for ind, i in enumerate(list(predictor.predict(train_ds, num_samples=1))):\n",
        "    t = sample_df(i)\n",
        "    t['object_id'] = o[ind]\n",
        "    t.columns = ['pred', 'object_id']\n",
        "    dfs.append(t)\n",
        "\n",
        "pd.concat(dfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5y72W--zGol"
      },
      "source": [
        "for i in df.object_id.unique():\n",
        "    plot_length = 150\n",
        "    prediction_intervals = (50.0, 90.0)\n",
        "    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n",
        "\n",
        "    t = df[df.object_id == i][['ne_date', 'kpi_value']]\n",
        "    t.set_index('ne_date')\n",
        "    t.plot(color='g')\n",
        "    plt.grid(which=\"both\")\n",
        "    plt.legend(legend, loc=\"upper left\")\n",
        "    # print(df[df.object_id == i].kpi_value)\n",
        "    # break\n",
        "    # plot_prob_forecast(pd.to_datetime(df[df.object_id == i].ne_date).dt.day, df[df.object_id == i].kpi_value, str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3B4a6vrz0QZ"
      },
      "source": [
        "next(iter(train_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQgRSL83NTE8"
      },
      "source": [
        "list(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA15xXc-NA1l"
      },
      "source": []
    }
  ]
}